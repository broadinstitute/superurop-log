{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireModule(nn.Module):\n",
    "    def __init__(self, in_c: int, out_c: int):\n",
    "        super().__init__(self)\n",
    "        # first point-wise convolution: 1x1\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_c, out_channels=in_c // 2, kernel_size=(1, 1), stride=2)\n",
    "        # first independent conv: 3x3\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_c // 2, out_channels=out_c // 2, kernel_size=(3, 3), stride=2)\n",
    "        # second independent (pointwise) conv: 1x1\n",
    "        self.conv3 = nn.Conv2d(in_channels=in_c // 2, out_channels=out_c // 2, kernel_size=(1, 1), stride=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = nn.ReLU(self.conv1(x))\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.conv3(x)\n",
    "        x = nn.ReLU(x1 + x2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposedFireModule(nn.Module):\n",
    "    def __init__(self, out_c: int, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels= , out_channels=out_c * 2, kernel_size=(1, 1), stride=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=out_c * 2, out_channels=out_c, kernel_size=(1, 1), stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=out_c * 2, out_channels=out_c, kernel_size=(1, 1), stride=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.conv3(x)\n",
    "\n",
    "        return x1 + x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self, x_concat: int, out_c: int, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.x_concat = x_concat\n",
    "\n",
    "        self.transposed_fire_mod = TransposedFireModule(out_c = out_c * 4)\n",
    "        self.fire_mods = nn.Sequential(\n",
    "            FireModule(in_c= out_c * 4, out_c= out_c * 2),\n",
    "            FireModule(in_c= out_c * 2, out_c=out_c),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_transposed_fire = self.transposed_fire_mod(x)\n",
    "        x = x_transposed_fire + self.x_concat\n",
    "        x = self.fire_mods(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeUnet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__(self)\n",
    "        # first two 3x3 conv layers (3, 3, 64)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=2)\n",
    "\n",
    "        # downsample block: 2 fire modules\n",
    "        self.downsample = nn.Sequential(\n",
    "            FireModule(in_c=64, out_c=128),\n",
    "            FireModule(in_c=128, out_c=256),\n",
    "        )\n",
    "\n",
    "        self.up_sample = lambda x, out_c: UpSample(x, out_c)\n",
    "\n",
    "        self.t_conv = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(2, 2), stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=2)\n",
    "        self.conv4 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=2)\n",
    "        self.conv5 = nn.ConvTranspose2d(in_channels=64, out_channels=num_classes, kernel_size=(1, 1), stride=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = nn.ReLU(self.conv(x))\n",
    "        x_conv1 = nn.ReLU(self.conv2(x)) # skip connection to last concat after upsample\n",
    "\n",
    "        # 3 downsampling steps\n",
    "        x_ds1 = self.downsample(x_conv1) # skip connection to UpSample(US) #3\n",
    "        x_ds2 = self.downsample(x_ds1) # skip connection to US #2\n",
    "        x_ds3 = self.downsample(x_ds2) # skip connection to US #1\n",
    "        x_ds4 = self.downsample(x_ds3)\n",
    "\n",
    "        # 3 upsampling steps\n",
    "        us1 = self.up_sample(x_ds3, out_c = 4096)\n",
    "        x_us1 = us1(x_ds4)\n",
    "\n",
    "        us2 = self.up_sample(x_ds2, out_c = 1024)\n",
    "        x_us2 = us2(x_us1)\n",
    "\n",
    "        us3 = self.up_sample(x = x_ds1, out_c = 64)\n",
    "        x_us3 = us3(x_us2)\n",
    "\n",
    "        # post (after downsampling + upsampling)\n",
    "        x = nn.ReLU(self.t_conv(x_us3))\n",
    "        x = x + x_conv1\n",
    "        x = nn.ReLU(self.conv3(x))\n",
    "        x = nn.ReLU(self.conv4(x))\n",
    "        x = nn.ReLU(self.conv5(x))\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
