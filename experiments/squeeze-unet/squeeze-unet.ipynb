{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireModule(nn.Module):\n",
    "    def __init__(self, in_c: int, squeeze_c: int, out_c: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "        # for all layers below, stride is default = 1\n",
    "\n",
    "        # first point-wise convolution: 1x1\n",
    "        self.squeeze = nn.Conv2d(in_channels=in_c, out_channels=squeeze_c, kernel_size=1, stride=stride)\n",
    "        # first independent conv: 3x3\n",
    "        self.expand1x1 = nn.Conv2d(in_channels=squeeze_c, out_channels=out_c // 2, kernel_size=3, padding=1)\n",
    "        # second independent (pointwise) conv: 1x1\n",
    "        self.expand3x3 = nn.Conv2d(in_channels=squeeze_c, out_channels=out_c // 2, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.squeeze(x))\n",
    "        x = torch.cat([\n",
    "            F.relu(self.expand1x1(x)),\n",
    "            F.relu(self.expand3x3(x)),\n",
    "        ], dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "\n",
    "    def __init__(self, in_c: int, squeeze_c: int, out_c: int):\n",
    "        super().__init__()\n",
    "        self.fire_mods = nn.Sequential(\n",
    "            FireModule(in_c=in_c, squeeze_c=squeeze_c, out_c=out_c // 2, stride=2),\n",
    "            FireModule(in_c=out_c // 2, squeeze_c=squeeze_c * 2, out_c=out_c, stride=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fire_mods(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransposedFireModule(nn.Module):\n",
    "    def __init__(self, in_c: int, squeeze_c: int, out_c: int, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.t_squeeze_1x1 = nn.ConvTranspose2d(in_channels=in_c, out_channels=squeeze_c, kernel_size=1, stride=2, padding=0, output_padding=1)  # not sure of this\n",
    "        # self.t_squeeze_1x1 = nn.ConvTranspose2d(in_channels=in_c, out_channels=squeeze_c, kernel_size=1, stride=4)  # not sure of this\n",
    "        self.t_expand_1x1 = nn.ConvTranspose2d(in_channels=squeeze_c, out_channels=out_c // 2, kernel_size=2, stride=2, padding=0, output_padding=0) # not sure of this\n",
    "        self.t_expand_2x2 = nn.ConvTranspose2d(in_channels=squeeze_c, out_channels=out_c // 2, kernel_size=2, stride=2, padding=0)  # not sure of this\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # squeeze\n",
    "        x = F.relu(self.t_squeeze_1x1(x))\n",
    "        # inception stage\n",
    "        x = torch.cat([\n",
    "            F.relu(self.t_expand_1x1(x)),\n",
    "            F.relu(self.t_expand_2x2(x)),\n",
    "        ], dim=1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_c: int, t_fire_mod_out_c: int, out_c: int):\n",
    "        super().__init__()\n",
    "        self.t_fire_mod = TransposedFireModule(in_c=in_c, squeeze_c=in_c // 2, out_c=t_fire_mod_out_c)\n",
    "        self.fire_mods = nn.Sequential(\n",
    "            FireModule(in_c=t_fire_mod_out_c * 2,  # twice since transpose fire mod output is concatenated\n",
    "                       squeeze_c=t_fire_mod_out_c, # squeeze with half the input size\n",
    "                       out_c=out_c * 2,\n",
    "                       stride=1),\n",
    "            FireModule(in_c=out_c * 2, squeeze_c=out_c, out_c=out_c, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x1: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.t_fire_mod(x)\n",
    "        x = torch.cat([x, x1,], dim=1)\n",
    "        x = self.fire_mods(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeUnet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # first two 3x3 conv layers (3, 3, 64)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        # contracting step\n",
    "        self.ds1 = DownSample(in_c=64, squeeze_c=32, out_c=256)\n",
    "        self.ds2 = DownSample(in_c=256, squeeze_c=48, out_c=1_024)\n",
    "        self.ds3 = DownSample(in_c=1_024, squeeze_c=64, out_c=4_096)\n",
    "        self.ds4 = DownSample(in_c=4_096, squeeze_c=80, out_c=16_384)\n",
    "\n",
    "        # expanding step\n",
    "        self.us1 = UpSample(in_c=16_384, t_fire_mod_out_c=4_096, out_c=2_048)\n",
    "        self.us2 = UpSample(in_c=2_048, t_fire_mod_out_c=1_024, out_c=512)\n",
    "        self.us3 = UpSample(in_c=512, t_fire_mod_out_c=256, out_c=128)\n",
    "\n",
    "        self.t_conv = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=4, output_padding=2)  # not sure about this\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.outc = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # pre steps\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x_conv1 = F.relu(self.conv2(x)) # skip connection to last concat after upsample\n",
    "\n",
    "        # 4 downsampling steps\n",
    "        x_ds1 = self.ds1(x=x_conv1)  # skip connection to UpSample(US) #3\n",
    "        x_ds2 = self.ds2(x=x_ds1)  # skip connection to US #2\n",
    "        x_ds3 = self.ds3(x=x_ds2)  # skip connection to US #1\n",
    "        x_ds4 = self.ds4(x=x_ds3)\n",
    "\n",
    "        # 3 upsampling steps\n",
    "        x = self.us1(x_ds4, x_ds3)\n",
    "        x = self.us2(x, x_ds2)\n",
    "        x = self.us3(x, x_ds1)\n",
    "\n",
    "        # # post steps\n",
    "        x = F.relu(self.t_conv(x))\n",
    "        x = torch.cat([x, x_conv1], dim=1)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        logits = F.relu(self.outc(x))\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 512, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(1, 3, 512, 512)\n",
    "sq_unet = SqueezeUnet(num_classes=2)\n",
    "sq_unet(t).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
